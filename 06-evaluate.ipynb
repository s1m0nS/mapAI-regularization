{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook to evaluate results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from imutils import paths\n",
    "import time\n",
    "import glob\n",
    "\n",
    "import tifffile as tiff\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import jaccard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# TEST IMAGES:  1368\n",
      "# PREDICTIONS:  1368\n",
      "# REGULARIZATIONS:  1368\n"
     ]
    }
   ],
   "source": [
    "# CONFIGURE PATHS\n",
    "GD_PATH = os.getcwd() + \"/\"\n",
    "PLOT_PATH = GD_PATH + \"plots/\"\n",
    "\n",
    "# TEST\n",
    "# Task 1: \n",
    "TEST_IMG_DIR = \"/home/shymon/datasets/mapai_full/task1_test/images/\"\n",
    "TEST_MASK_DIR = \"/home/shymon/datasets/mapai_full/task1_test/masks/\"\n",
    "\n",
    "# TEST\n",
    "test_images = sorted(list(paths.list_images(TEST_IMG_DIR)))\n",
    "test_masks = sorted(list(paths.list_images(TEST_MASK_DIR)))\n",
    "\n",
    "PREDICTIONS_DIR = GD_PATH + \"predictions/\"\n",
    "REGULARIZATION_DIR = GD_PATH + \"regularizations/\"\n",
    "\n",
    "# read predictions\n",
    "predictions = glob.glob(PREDICTIONS_DIR + \"*.tif\")\n",
    "predictions.sort()\n",
    "\n",
    "# read regularizations\n",
    "regularizations = glob.glob(REGULARIZATION_DIR + \"*.tif\")\n",
    "regularizations.sort()\n",
    "\n",
    "print(\"# TEST IMAGES: \", len(test_images))\n",
    "print(\"# PREDICTIONS: \", len(predictions))\n",
    "print(\"# REGULARIZATIONS: \", len(predictions))\n",
    "\n",
    "# Project Regularization directory\n",
    "projectRegDir = GD_PATH + \"projectRegularization\" + \"/\"\n",
    "\n",
    "ptw = projectRegDir + \"pretrained_weights\" + \"/\"\n",
    "\n",
    "# GET THE PATHS FOR TRAINED GAN MODELS\n",
    "ENCODER = ptw + \"E140000_e1\"\n",
    "GENERATOR = ptw + \"E140000_net\"\n",
    "\n",
    "# print(ENCODER)\n",
    "# print(GENERATOR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Intersection over Union on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(gt_mask, pred_mask):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculates the intersection over union (BIoU) between two binary semantic segmentation masks.\n",
    "    \n",
    "    Arguments:\n",
    "    mask1 -- a 2D numpy array representing the first mask\n",
    "    mask2 -- a 2D numpy array representing the second mask\n",
    "    \n",
    "    Returns:\n",
    "    iou -- a float representing the BIoU between the two masks\n",
    "    \"\"\"\n",
    "\n",
    "    intersection  = np.logical_and(gt_mask, pred_mask).sum()\n",
    "    union = np.logical_or(gt_mask, pred_mask).sum()\n",
    "    iou_score = intersection / union if union != 0 else np.nan\n",
    "\n",
    "    return iou_score\n",
    "\n",
    "def biou(segA, segB, boundary_width=1):\n",
    "    \"\"\"\n",
    "    Calculate the Boundary Intersection over Union (BIoU) metric between two binary segmentation masks.\n",
    "\n",
    "    Parameters:\n",
    "    segA (numpy array): A 2-dimensional binary numpy array representing the first segmentation mask.\n",
    "    segB (numpy array): A 2-dimensional binary numpy array representing the second segmentation mask.\n",
    "    boundary_width (int): The width of the boundary region to be included in the calculation (default is 1).\n",
    "\n",
    "    Returns:\n",
    "    float: The BIoU metric between the two segmentation masks.\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute the boundaries of the segmentation masks\n",
    "    boundaryA = np.zeros_like(segA)\n",
    "    boundaryA[:,boundary_width:-boundary_width] = segA[:,boundary_width:-boundary_width] ^ segA[:, :-2*boundary_width] ^ segA[:, 2*boundary_width:]\n",
    "    boundaryA[boundary_width:-boundary_width,:] = boundaryA[boundary_width:-boundary_width,:] ^ segA[:-2*boundary_width,:] ^ segA[2*boundary_width:,:]\n",
    "\n",
    "    boundaryB = np.zeros_like(segB)\n",
    "    boundaryB[:,boundary_width:-boundary_width] = segB[:,boundary_width:-boundary_width] ^ segB[:, :-2*boundary_width] ^ segB[:, 2*boundary_width:]\n",
    "    boundaryB[boundary_width:-boundary_width,:] = boundaryB[boundary_width:-boundary_width,:] ^ segB[:-2*boundary_width,:] ^ segB[2*boundary_width:,:]\n",
    "\n",
    "    # Compute the coordinates of the intersection boundary\n",
    "    intersection_boundary = boundaryA & boundaryB\n",
    "\n",
    "    # Compute the coordinates of the union boundary\n",
    "    union_boundary = boundaryA | boundaryB\n",
    "\n",
    "    # Compute the area of intersection boundary\n",
    "    intersection_boundary_area = np.count_nonzero(intersection_boundary)\n",
    "\n",
    "    # Compute the area of union boundary\n",
    "    union_boundary_area = np.count_nonzero(union_boundary)\n",
    "\n",
    "    # Compute the intersection and union of the interior regions\n",
    "    intersection = np.logical_and(segA, segB)\n",
    "    union = np.logical_or(segA, segB)\n",
    "\n",
    "    # Compute the area of intersection and union of the interior regions\n",
    "    intersection_area = np.count_nonzero(intersection)\n",
    "    union_area = np.count_nonzero(union)\n",
    "\n",
    "    # Compute the BIoU metric\n",
    "    biou = (intersection_area + intersection_boundary_area) / (union_area + union_boundary_area + 1e-6)\n",
    "\n",
    "    return biou\n",
    "\n",
    "# To read the original test images from MapAI\n",
    "def test2arr(tif_img):\n",
    "    img = tiff.imread(tif_img)\n",
    "    arr = np.array(img)\n",
    "    return arr\n",
    "\n",
    "# To read the predictions and regularizations\n",
    "def pr2arr(tif_img):\n",
    "    img = tiff.imread(tif_img)\n",
    "    img = img / 255\n",
    "    img = cv2.resize(img, (500, 500))\n",
    "    arr = np.array(img)\n",
    "    arr = arr.astype(np.uint8)\n",
    "    return arr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on single image by choice"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Without regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard score or IoU with Scikit-learn:  0.7001\n",
      "Jaccard score or IoU with manual function:  0.7001\n",
      "Boundary Intersection over Union:  0.6959\n"
     ]
    }
   ],
   "source": [
    "n = 900\n",
    "\n",
    "jaccard_sklearn = jaccard_score(test2arr(test_masks[n]), pr2arr(predictions[n]), average='micro')\n",
    "print(\"Jaccard score or IoU with Scikit-learn: \", round(jaccard_sklearn, 4))\n",
    "\n",
    "iou_man = iou(test2arr(test_masks[n]), pr2arr(predictions[n]))\n",
    "print(\"Jaccard score or IoU with manual function: \", round(iou_man, 4))\n",
    "\n",
    "biou_man = biou(test2arr(test_masks[n]), pr2arr(predictions[n]))\n",
    "print(\"Boundary Intersection over Union: \", round(biou_man, 4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) With regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard score or IoU with Scikit-learn:  0.6841\n",
      "Jaccard score or IoU with manual function:  0.6841\n",
      "Boundary Intersection over Union:  0.6801\n"
     ]
    }
   ],
   "source": [
    "n = 900\n",
    "\n",
    "jaccard_sklearn = jaccard_score(test2arr(test_masks[n]), pr2arr(regularizations[n]), average='micro')\n",
    "print(\"Jaccard score or IoU with Scikit-learn: \", round(jaccard_sklearn, 4))\n",
    "\n",
    "iou_man = iou(test2arr(test_masks[n]), pr2arr(regularizations[n]))\n",
    "print(\"Jaccard score or IoU with manual function: \", round(iou_man, 4))\n",
    "\n",
    "biou_man = biou(test2arr(test_masks[n]), pr2arr(regularizations[n]))\n",
    "print(\"Boundary Intersection over Union: \", round(biou_man, 4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on entire MapAI dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Without regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation without regularization: \n",
      "Mean IoU for Task 1:  0.3995\n",
      "Mean BIoU for Task 1:  0.3766\n",
      "S metric for Task 1:  0.3881\n"
     ]
    }
   ],
   "source": [
    "iou_mapai = np.array([])\n",
    "biou_mapai = np.array([])\n",
    "\n",
    "for n in range(len(test_masks)):\n",
    "    \n",
    "    # Calculate metrics\n",
    "\n",
    "    # IoU\n",
    "    iou_single = iou(test2arr(test_masks[n]), pr2arr(predictions[n]))\n",
    "\n",
    "    # BIoU\n",
    "    biou_single = biou(test2arr(test_masks[n]), pr2arr(predictions[n]))\n",
    "\n",
    "    # Append to whole array\n",
    "    iou_mapai = np.append(iou_mapai, iou_single)\n",
    "    biou_mapai = np.append(biou_mapai, biou_single)\n",
    "\n",
    "#iou_mapai = iou_mapai[iou_mapai != 0]\n",
    "#biou_mapai = biou_mapai[biou_mapai != 0]\n",
    "\n",
    "print(\"Evaluation without regularization: \")\n",
    "print(\"Mean IoU for Task 1: \", round(np.nanmean(iou_mapai), 4))\n",
    "print(\"Mean BIoU for Task 1: \", round(np.nanmean(biou_mapai), 4))\n",
    "print(\"S metric for Task 1: \", round(((np.nanmean(biou_mapai) + np.nanmean(iou_mapai)) / 2 ), 4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) With regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean IoU for Task 1:  0.4017\n",
      "Mean BIoU for Task 1:  0.378\n",
      "S metric for Task 1:  0.3898\n"
     ]
    }
   ],
   "source": [
    "iou_mapai = np.array([])\n",
    "biou_mapai = np.array([])\n",
    "\n",
    "for n in range(len(test_masks)):\n",
    "    \n",
    "    # Calculate metrics\n",
    "\n",
    "    # IoU\n",
    "    iou_single = iou(test2arr(test_masks[n]), pr2arr(regularizations[n]))\n",
    "\n",
    "    # BIoU\n",
    "    biou_single = biou(test2arr(test_masks[n]), pr2arr(regularizations[n]))\n",
    "\n",
    "    # Append to whole array\n",
    "    iou_mapai = np.append(iou_mapai, iou_single)\n",
    "    biou_mapai = np.append(biou_mapai, biou_single)\n",
    "\n",
    "#iou_mapai = iou_mapai[iou_mapai != 0]\n",
    "#biou_mapai = biou_mapai[biou_mapai != 0]\n",
    "\n",
    "print(\"Mean IoU for Task 1: \", round(np.nanmean(iou_mapai), 4))\n",
    "print(\"Mean BIoU for Task 1: \", round(np.nanmean(biou_mapai), 4))\n",
    "print(\"S metric for Task 1: \", round(((np.nanmean(biou_mapai) + np.nanmean(iou_mapai)) / 2 ), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5614dd747bc595cf94d4c937a609d8df6c75b545807dd5ca7f02df8b67f4ea7c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
